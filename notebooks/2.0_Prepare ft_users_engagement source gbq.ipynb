{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GOALS\n",
    "To create a GBQ view containing a daily state on users engagement.\n",
    "- generate dates index\n",
    "- generate users and dates index\n",
    "- fill last_login_date for each date/user key\n",
    "- fill last_consumption_start_date for each date/user key\n",
    "- fill last_consumption_completion_date for each date/user key"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PACKAGES"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "from google.oauth2 import service_account\n",
    "import pandas_gbq\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PARAMETERS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "project_id = \"analytics-dev-308300\"\n",
    "destination_table='raw_engagement.users_engagement'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#notebook only\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file('../keys/gcp_key.json')\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.getcwd().replace('notebooks','keys/gcp_key.json')\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ],
   "outputs": [],
   "metadata": {
    "active": "ipynb"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FUNCTIONS"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def get_data(project_id):\n",
    "    \"\"\"\n",
    "    ()-->df\n",
    "    \"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT\n",
    "            user_id,\n",
    "            created_at,\n",
    "            extraction_date,\n",
    "            user_name\n",
    "        FROM\n",
    "            dtm_engagement.dim_users\n",
    "        WHERE\n",
    "            group_id=1818\n",
    "            AND association IS NULL\n",
    "    \"\"\"\n",
    "    users_df = pd.read_gbq(\n",
    "        query=query,project_id=project_id)\n",
    "\n",
    "    users_lst = users_df['user_id'].tolist()\n",
    "\n",
    "    creation_df= users_df[['user_id','created_at']].drop_duplicates(ignore_index=True)\n",
    "    creation_df['created_at']=pd.to_datetime(\n",
    "        creation_df['created_at'], utc=True\n",
    "        )\n",
    "\n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT\n",
    "            user_id,\n",
    "            days_since_last_login,\n",
    "            extraction_date,\n",
    "            enabled\n",
    "        FROM\n",
    "            dtm_engagement.hist_users\n",
    "        WHERE\n",
    "            group_id=1818\n",
    "        ORDER BY\n",
    "            extraction_date DESC\n",
    "        \"\"\"\n",
    "\n",
    "    login_df = pd.read_gbq(\n",
    "        query=query, project_id=project_id)\n",
    "\n",
    "    login_df=login_df.drop_duplicates(subset=['user_id','extraction_date'],keep='last',ignore_index=True)\n",
    "\n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT\n",
    "            user_id,\n",
    "            set_id,\n",
    "            started_at,\n",
    "            completed_at\n",
    "        FROM\n",
    "            dtm_engagement.ft_content_consumption\n",
    "        WHERE\n",
    "            group_id=1818\n",
    "        \"\"\"\n",
    "    consumption_df = pd.read_gbq(\n",
    "        query=query, project_id=project_id\n",
    "    )\n",
    "\n",
    "    consumption_df[\"started_at\"] = pd.to_datetime(\n",
    "        consumption_df[\"started_at\"], utc=True\n",
    "    )\n",
    "    consumption_df[\"completed_at\"] = pd.to_datetime(\n",
    "        consumption_df[\"completed_at\"], utc=True\n",
    "    )\n",
    "\n",
    "    return users_lst, creation_df, login_df, consumption_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## generate base (users and dates) data frame"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def create_base_df(\n",
    "    users_ls,\n",
    "    creation_df,\n",
    "    start_date=\"2021-08-16\",\n",
    "    end_date=pd.Timestamp.today(tz='UTC').strftime(\"%Y-%m-%d\"),\n",
    "):\n",
    "    \"\"\"\n",
    "    (date-like, date_like, series) --> df\n",
    "    Create a dataframe with one row for each combination of user and date. Date range is defined by start_date and end_date (excluded).\n",
    "    \"\"\"\n",
    "    dates_index = (\n",
    "        pd.to_datetime(\n",
    "            pd.date_range(start=start_date, end=end_date, name=\"action_date\")\n",
    "        )\n",
    "        .strftime(\"%Y-%m-%d\")\n",
    "        .to_list()\n",
    "    )\n",
    "\n",
    "    actions_dict = [\n",
    "        {\"action_date\": action_date, \"user_id\": user}\n",
    "        for action_date in dates_index\n",
    "        for user in users_ls\n",
    "    ]\n",
    "\n",
    "    base_df=pd.DataFrame(actions_dict)\n",
    "    base_df=base_df.merge(creation_df, how='left',on='user_id')\n",
    "\n",
    "    base_df=base_df.drop(index=base_df[base_df['created_at'].dt.strftime('%Y-%m-%d')>base_df['action_date']].index)\n",
    "    \n",
    "    return base_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## fill max date of interest for each date/user key"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def max_date(consumption_df, reporting_date, user_id, date_of_interest):\n",
    "    \"\"\"\n",
    "    (df,date like str, int)-->date\n",
    "    Select the maximum value for date_of_interest field that is inferior to the reporting date (23:59:59), for the specified user_id.\n",
    "    \"\"\"\n",
    "    max_start = consumption_df[\n",
    "        (consumption_df[\"user_id\"] == user_id)\n",
    "        & (\n",
    "            consumption_df[date_of_interest]\n",
    "            <= pd.Timestamp(reporting_date + \" 23:59:59\", tz=\"UTC\")\n",
    "        )\n",
    "    ][date_of_interest].max()\n",
    "\n",
    "    return max_start"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fill the number of completed sets by period"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def calculate_nb_of_sets_of_interest(consumption_df,reporting_date,user_id,date_of_interest,nb_of_days):\n",
    "    \"\"\"\n",
    "    (df, date like str, int, int, date like str)-->int\n",
    "    For the user_id, count the number of set_ids where completed at is between reporting_date-number_of_days and reporting_date.\n",
    "    \"\"\"\n",
    "\n",
    "    number_of_sets = (consumption_df[(consumption_df['user_id']==user_id) & \n",
    "                                    (consumption_df[date_of_interest].between(\n",
    "                                        pd.Timestamp(reporting_date + \" 23:59:59\", tz=\"UTC\")\n",
    "                                        -pd.Timedelta(nb_of_days,'days'),\n",
    "                                        pd.Timestamp(reporting_date + \" 23:59:59\", tz=\"UTC\")\n",
    "                                        ))]['set_id'].count())\n",
    "    \n",
    "    return number_of_sets"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set user status based on dates"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def user_status(days_since_last_login, days_since_last_start,days_since_last_completion,enabled):\n",
    "    \"\"\"\n",
    "    (timedelta,timedelta,timedelta,bool)--> str\n",
    "    \"\"\"\n",
    "    if enabled==False:\n",
    "        return '0.stone'\n",
    "    elif days_since_last_completion <= 7:\n",
    "        return '5.learner'\n",
    "    elif days_since_last_start <= 7:\n",
    "        return '4.consumer'\n",
    "    elif days_since_last_login <= 7:\n",
    "        return '3.curious'\n",
    "    elif days_since_last_login > 7 or days_since_last_completion>0 or days_since_last_start>0:\n",
    "        return '2.missing'\n",
    "    elif (days_since_last_login>-1)==False:\n",
    "        return '1.bird'\n",
    "    else:\n",
    "        return 'weird'\n",
    "\n",
    "# assert user_status(\n",
    "#     timedelta_since_last_login=pd.Timedelta(pd.NaT),\n",
    "#     timedelta_since_last_start=pd.Timedelta('2 days 13:41:36'),\n",
    "#     timedelta_since_last_completion=pd.Timedelta('1 days 11:29:23'),\n",
    "#     ever_logged=True)=='4.learner'\n",
    "\n",
    "# assert user_status(\n",
    "#     timedelta_since_last_login=pd.Timedelta(pd.NaT),\n",
    "#     timedelta_since_last_start=pd.Timedelta('1 days 13:41:36'),\n",
    "#     timedelta_since_last_completion=pd.Timedelta('7 days 11:29:23'),\n",
    "#     ever_logged=True)=='3.consumer'\n",
    "\n",
    "# assert user_status(\n",
    "#     timedelta_since_last_login=pd.Timedelta(pd.NaT),\n",
    "#     timedelta_since_last_start=pd.Timedelta('1 days 13:41:36'),\n",
    "#     timedelta_since_last_completion=pd.Timedelta(pd.NaT),\n",
    "#     ever_logged=True)=='3.consumer'\n",
    "\n",
    "# # assert user_status(\n",
    "# #     timedelta_since_last_login=pd.Timedelta('1 days 13:41:36'),\n",
    "# #     timedelta_since_last_start=pd.Timedelta('8 days 13:41:36'),\n",
    "# #     timedelta_since_last_completion=pd.Timedelta('7 days 11:29:23'),\n",
    "# #     ever_logged=True)=='2.curious'\n",
    "\n",
    "# assert user_status(\n",
    "#     timedelta_since_last_login=pd.Timedelta('7 days 13:41:36'),\n",
    "#     timedelta_since_last_start=pd.Timedelta('8 days 13:41:36'),\n",
    "#     timedelta_since_last_completion=pd.Timedelta('10 days 11:29:23'),\n",
    "#     ever_logged=True)=='1.missing'\n",
    "\n",
    "# assert user_status(\n",
    "#     timedelta_since_last_login=pd.Timedelta('0 days'),\n",
    "#     timedelta_since_last_start=pd.Timedelta('0 days'),\n",
    "#     timedelta_since_last_completion=pd.Timedelta('0 days'),\n",
    "#     ever_logged=False)=='0.bird'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## create engagement df by completing base_df with calculated fields"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def generate_engagement_df(base_df,consumption_df,login_df):\n",
    "    \"\"\"\n",
    "    (df,df,df)-->df\n",
    "    \"\"\"\n",
    "    engagement_df=base_df.copy()\n",
    "    \n",
    "    engagement_df=(pd.merge(\n",
    "            engagement_df,\n",
    "            login_df,\n",
    "            how='left',\n",
    "            left_on=['user_id','action_date'],\n",
    "            right_on=['user_id','extraction_date'])\n",
    "        .drop(columns='extraction_date'))\n",
    "    \n",
    "    engagement_df['last_start_date']=engagement_df.apply(lambda x: max_date(consumption_df,x['action_date'],x['user_id'],'started_at'), axis=1)\n",
    "    engagement_df['timedelta_since_last_start']=pd.to_datetime(engagement_df['action_date']+' 23:59:59',utc=True)-engagement_df['last_start_date']\n",
    "    engagement_df['days_since_last_start']=engagement_df['timedelta_since_last_start'].dt.days\n",
    "    \n",
    "    engagement_df['last_completion_date']=engagement_df.apply(lambda x: max_date(consumption_df,x['action_date'],x['user_id'],'completed_at'), axis=1)\n",
    "    engagement_df['timedelta_since_last_completion']=(\n",
    "        pd.to_datetime(engagement_df['action_date']+' 23:59:59',utc=True)-engagement_df['last_completion_date']\n",
    "            )\n",
    "    engagement_df['days_since_last_completion']=engagement_df['timedelta_since_last_completion'].dt.days\n",
    "    \n",
    "    engagement_df['nb_of_completed_sets']=engagement_df.apply(lambda x: calculate_nb_of_sets_of_interest(consumption_df=consumption_df,reporting_date=x['action_date'],user_id=x['user_id'],date_of_interest='completed_at',nb_of_days=7),axis=1)\n",
    "    \n",
    "    engagement_df['user_status']=engagement_df.apply(lambda x:\n",
    "                                                               user_status(\n",
    "                                                                   x['days_since_last_login'],\n",
    "                                                                   x['days_since_last_start'],\n",
    "                                                                   x['days_since_last_completion'],\n",
    "                                                                   x['enabled']),\n",
    "                                                               axis=1\n",
    "                                                              )\n",
    "    \n",
    "    return engagement_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## create user_engagement table in gbq"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def start(project_id=project_id, destination_table_name=destination_table):\n",
    "    \"\"\"\n",
    "    (df,str,str,str)--> gbq table\n",
    "    \"\"\"\n",
    "    \n",
    "    users_ls, creation_df, login_df, consumption_df = get_data(project_id=project_id)\n",
    "    \n",
    "    engagement_df = generate_engagement_df(\n",
    "                                create_base_df(users_ls=users_ls,\n",
    "                                               creation_df=creation_df),\n",
    "                                consumption_df=consumption_df,\n",
    "                                login_df=login_df\n",
    "                    )\n",
    "    \n",
    "    engagement_df.to_gbq(destination_table_name,project_id=project_id,if_exists='replace')\n",
    "    \n",
    "    return 'ft_user_engagement created'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA WRANGLING\n",
    "Notebook only"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "users_ls, creation_df, login_df, consumption_df = get_data(project_id=project_id)\n",
    "engagement_df = generate_engagement_df(\n",
    "                                create_base_df(users_ls=users_ls,\n",
    "                                               creation_df=creation_df),\n",
    "                                consumption_df=consumption_df,\n",
    "                                login_df=login_df\n",
    "                    )"
   ],
   "outputs": [],
   "metadata": {
    "active": "ipynb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m75"
  },
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('std_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true,
  "interpreter": {
   "hash": "cb1ba7f150d507ef1d1f1d30ab3b3b7b717d1d8faf2da1e077dd27ab2e32b187"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}